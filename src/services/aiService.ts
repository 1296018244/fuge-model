/**
 * Cloud-based AI Service
 * Uses OpenAI API directly with settings from Supabase
 */
import { cloudSettings, cloudAIConfigs } from '../hooks/supabaseStorage';
import type { AnalysisResult, PraiseResult, AIConfig } from '../types';

// Get AI config from cloud (Prioritize new ai_configs table)
async function getAIConfig(): Promise<{ apiKey: string; baseUrl: string; model: string, configId?: string }> {
    // 1. Try get active config from new table
    const activeConfig = await cloudAIConfigs.getActive();
    if (activeConfig) {
        return {
            apiKey: activeConfig.api_key,
            baseUrl: activeConfig.base_url,
            model: activeConfig.model_name,
            configId: activeConfig.id
        };
    }

    // 2. Fallback to legacy settings
    const config = await cloudSettings.fetchAll();
    return {
        apiKey: config.openai_api_key || '',
        baseUrl: config.openai_base_url || 'https://api.openai.com/v1',
        model: config.model_name || 'gpt-3.5-turbo'
    };
}

// å°è¯•åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨é…ç½®
async function switchToNextConfig(currentConfigId?: string): Promise<boolean> {
    if (!currentConfigId) return false;

    const allConfigs = await cloudAIConfigs.fetchAll();
    if (allConfigs.length <= 1) return false;

    // æ‰¾åˆ°å½“å‰é…ç½®çš„ç´¢å¼•
    const currentIndex = allConfigs.findIndex(c => c.id === currentConfigId);
    let nextIndex = (currentIndex + 1) % allConfigs.length;

    // ç®€å•è½®è¯¢ï¼šæ‰¾ä¸‹ä¸€ä¸ª
    const nextConfig = allConfigs[nextIndex];
    if (nextConfig && nextConfig.id !== currentConfigId) {
        console.log(`[AI] Auto-switching to config: ${nextConfig.name}`);
        await cloudAIConfigs.setActive(nextConfig.id);
        return true;
    }
    return false;
}

// Generic chat completion call with retry
async function chatCompletion(systemPrompt: string, userMessage: string, retryCount = 0): Promise<string> {
    const { apiKey, baseUrl, model, configId } = await getAIConfig();

    console.log(`[AI] Calling ${baseUrl} with model ${model} (Attempt ${retryCount + 1})`);

    if (!apiKey) {
        throw new Error('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® OpenAI API Key');
    }

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 60000); // 60s timeout

    try {
        const response = await fetch(`${baseUrl}/chat/completions`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                model,
                messages: [
                    { role: 'system', content: systemPrompt },
                    { role: 'user', content: userMessage }
                ],
                temperature: 0.7
            }),
            signal: controller.signal
        });

        clearTimeout(timeoutId);

        if (!response.ok) {
            // Check for 429 Rate Limit
            if (response.status === 429 && retryCount < 3) {
                console.warn(`[AI] Rate limit exceeded (429). Trying next config...`);
                const switched = await switchToNextConfig(configId);
                if (switched) {
                    return chatCompletion(systemPrompt, userMessage, retryCount + 1);
                }
            }

            const errorText = await response.text();
            console.error('[AI] API Error:', response.status, errorText);

            let friendlyMessage = `AI æœåŠ¡è¯·æ±‚å¤±è´¥ (${response.status})`;
            if (response.status === 401) {
                friendlyMessage = 'API Key æ— æ•ˆæˆ–è¿‡æœŸï¼Œè¯·åœ¨è®¾ç½®ä¸­æ£€æŸ¥';
            } else if (response.status === 429) {
                friendlyMessage = 'å½“å‰é…ç½®è¯·æ±‚æ¬¡æ•°è¶…é™ï¼Œä¸”æ— å…¶ä»–å¯ç”¨é…ç½®';
            } else if (response.status >= 500) {
                friendlyMessage = 'AI æœåŠ¡å™¨å¼€å°å·®äº†ï¼Œè¯·ç¨åé‡è¯•';
            }

            try {
                const errorJson = JSON.parse(errorText) as import('../types').AIErrorResponse;
                const backendMsg = errorJson.error && typeof errorJson.error !== 'string'
                    ? errorJson.error.message
                    : (typeof errorJson.error === 'string' ? errorJson.error : '');

                throw new Error(backendMsg || friendlyMessage);
            } catch (e: unknown) {
                // If it's already the Error we threw above, rethrow it
                if (e instanceof Error && e.message !== friendlyMessage && !e.message.includes('JSON')) {
                    throw e;
                }
                throw new Error(`${friendlyMessage}: ${errorText.substring(0, 50)}...`);
            }
        }

        const data = await response.json() as import('../types').AIChatCompletionResponse;
        const content = data.choices?.[0]?.message?.content;

        if (!content) {
            console.warn('[AI] Empty response content:', data);

            // Check for provider specific errors (e.g. iflow.cn / siliconflow)
            const statusStr = String(data.status || '');
            if ((data.status && data.msg) || statusStr === '435') {
                const msg = data.msg || (data.error ? JSON.stringify(data.error) : 'Unknown Error');
                const isModelError = msg.includes('Model not support') || statusStr === '435';

                if (isModelError) {
                    console.warn(`[AI] Model error detected (${msg}). Trying next config...`);
                    const switched = await switchToNextConfig(configId);
                    if (switched) {
                        return chatCompletion(systemPrompt, userMessage, retryCount + 1);
                    }
                    throw new Error(`AI æœåŠ¡å•†æŠ¥é”™: ${msg} (è¯·æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®)`);
                }
                throw new Error(`AI æœåŠ¡å•†æŠ¥é”™: ${msg}`);
            }

            // Check generic 'error' field in 200 OK response
            if (data.error) {
                const errorMsg = typeof data.error === 'string' ? data.error : (data.error.message || JSON.stringify(data.error));
                throw new Error(`AI API æŠ¥é”™: ${errorMsg}`);
            }

            throw new Error('AI è¿”å›äº†ç©ºå†…å®¹ï¼Œä¸”æ— æ˜ç¡®é”™è¯¯ä¿¡æ¯');
        }

        return content;

    } catch (error: unknown) {
        clearTimeout(timeoutId);
        console.error('[AI] Request Failed:', error);

        if (error instanceof Error) {
            if (error.name === 'AbortError') {
                throw new Error('AI è¯·æ±‚è¶…æ—¶ (60ç§’)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•');
            }
            if (error.message === 'Failed to fetch') {
                throw new Error('æ— æ³•è¿æ¥åˆ° AI æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– Base URL è®¾ç½®');
            }
            throw error;
        }
        throw new Error(String(error));
    }
}

// Helper to clean markdown formatting from JSON string
function cleanJsonResponse(str: string): string {
    if (!str) return '{}';
    // Remove markdown code blocks: ```json, ``` json, ````json, etc. (any backticks, optional space, optional language tag)
    let cleaned = str.replace(/`{3,}\s*json\s*/gi, '').replace(/\s*`{3,}/g, '');
    // Sometimes there's explanation text before/after, try to find the first { and last }
    const firstBrace = cleaned.indexOf('{');
    const lastBrace = cleaned.lastIndexOf('}');
    if (firstBrace !== -1 && lastBrace !== -1) {
        cleaned = cleaned.substring(firstBrace, lastBrace + 1);
    }
    return cleaned.trim();
}

// Behavior analysis for BehaviorWizard
export const analyzeBehavior = async (
    behavior: string,
    motivation: number,
    ability: number
): Promise<AnalysisResult> => {
    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¡Œä¸ºè®¾è®¡é¡¾é—®ï¼ŒåŸºäºç¦æ ¼è¡Œä¸ºæ¨¡å‹å¸®åŠ©ç”¨æˆ·å»ºç«‹å¾®ä¹ æƒ¯ã€‚
    
è¯·åˆ†æç”¨æˆ·æƒ³è¦å»ºç«‹çš„è¡Œä¸ºï¼Œå¹¶æä¾›ï¼š
1. åˆ†æè¿™ä¸ªè¡Œä¸ºç›®å‰çš„å¯è¡Œæ€§
2. å»ºè®®ä¸€ä¸ªæ›´å¾®å°ã€æ›´å®¹æ˜“æ‰§è¡Œçš„ç‰ˆæœ¬
3. è®¾è®¡ä¸€ä¸ª"é”šç‚¹+å¾®è¡Œä¸º"çš„é…æ–¹

ä»¥çº¯JSONæ ¼å¼å›å¤ï¼ˆä¸è¦Markdownæ ¼å¼ï¼‰ï¼š
{
  "analysis": "å¯¹è¡Œä¸ºçš„ç®€çŸ­åˆ†æ",
  "suggestion": "å¦‚ä½•è®©è¿™ä¸ªè¡Œä¸ºæ›´å®¹æ˜“æ‰§è¡Œçš„å»ºè®®ï¼ˆmarkdownæ ¼å¼ï¼‰",
  "recipe": {
    "anchor": "è§¦å‘è¡Œä¸ºçš„é”šç‚¹ï¼Œå¦‚'å½“æˆ‘åˆ·å®Œç‰™å'",
    "tiny_behavior": "æç®€ç‰ˆæœ¬çš„è¡Œä¸ºï¼Œå¦‚'åš2ä¸ªæ·±è¹²'"
  },
  "environment_setup": ["ä¸ºæˆåŠŸå‡†å¤‡ç¯å¢ƒçš„å»ºè®®1", "å»ºè®®2"]
}`;

    const userMessage = `è¡Œä¸º: ${behavior}\nåŠ¨æœºåˆ†æ•°: ${motivation}/10\nèƒ½åŠ›åˆ†æ•°: ${ability}/10`;

    let response = '';
    try {
        response = await chatCompletion(systemPrompt, userMessage);
        const cleaned = cleanJsonResponse(response);
        console.log('[AI] Raw Response:', response);
        console.log('[AI] Cleaned Response:', cleaned);

        const parsed = JSON.parse(cleaned);
        return {
            behavior,
            score: Math.min(motivation, ability),
            suggestion: parsed.suggestion || '',
            analysis: parsed.analysis,
            recipe: parsed.recipe,
            environment_setup: parsed.environment_setup
        };
    } catch (e: any) {
        console.error('[AI] Parse Error:', e);

        // Fallback for JSON parse errors
        if (e.message?.includes('JSON')) {
            return {
                behavior,
                score: Math.min(motivation, ability),
                suggestion: `AI è¿”å›æ ¼å¼å¯èƒ½æœ‰è¯¯ï¼Œæ— æ³•è§£æä¸º JSONã€‚\n\nåŸå§‹å›å¤:\n${response}`,
                analysis: 'è§£æé”™è¯¯'
            };
        }
        throw e;
    }
};

// Diagnosis for DiagnosisModal
export const diagnoseFailure = async (habit: any, reason: string): Promise<any> => {
    const systemPrompt = `ä½ æ˜¯ä¸€ä½è¡Œä¸ºä¹ æƒ¯åŒ»ç”Ÿï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è¯Šæ–­ä¸ºä»€ä¹ˆä¹ æƒ¯æ²¡æœ‰æ‰§è¡ŒæˆåŠŸï¼Œå¹¶æä¾›ä¿®å¤æ–¹æ¡ˆã€‚

æ ¹æ®ç”¨æˆ·æä¾›çš„ä¹ æƒ¯ä¿¡æ¯å’Œå¤±è´¥åŸå› ï¼Œç»™å‡ºï¼š
1. è¯Šæ–­ç»“æœ
2. ä¸€ä¸ªæ›´ç®€å•/æ›´é€‚åˆçš„æ–°æ–¹æ¡ˆ

ä»¥çº¯JSONæ ¼å¼å›å¤ï¼ˆä¸è¦Markdownæ ¼å¼ï¼‰ï¼š
{
  "diagnosis": "å¯¹å¤±è´¥åŸå› çš„ç®€çŸ­è¯Šæ–­",
  "new_plan": {
    "anchor": "æ–°çš„é”šç‚¹",
    "tiny_behavior": "æ›´ç®€å•çš„å¾®è¡Œä¸º"
  }
}`;

    const reasonMap: Record<string, string> = {
        'forgot': 'æˆ‘å¿˜è®°åšäº†',
        'hard': 'å¤ªéš¾äº†/å¤ªç´¯äº†',
        'unmotivated': 'è§‰å¾—æ²¡æ„ä¹‰',
        'ineffective': 'åšäº†ä½†æ²¡ç”¨'
    };

    const userMessage = `ä¹ æƒ¯ä¿¡æ¯ï¼š
- é”šç‚¹: ${habit.anchor}
- å¾®è¡Œä¸º: ${habit.tiny_behavior}
- åŸå§‹ç›®æ ‡: ${habit.original_behavior || '(æœªçŸ¥)'}

å¤±è´¥åŸå› : ${reasonMap[reason] || reason}`;

    let response = '';
    try {
        response = await chatCompletion(systemPrompt, userMessage);
        const cleaned = cleanJsonResponse(response);
        console.log('[AI] Diagnose Raw Response:', response);
        console.log('[AI] Diagnose Cleaned Response:', cleaned);
        return JSON.parse(cleaned);
    } catch (e: any) {
        console.error('[AI] Diagnose Error:', e);

        // Fallback for JSON parse errors
        if (e.message?.includes('JSON') || e.message?.includes('Unexpected')) {
            return {
                diagnosis: `AIè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œè¯·é‡è¯•ã€‚åŸå§‹å›å¤: ${response.substring(0, 100)}...`,
                new_plan: null
            };
        }
        throw e;
    }
};

// Praise for celebrations
export const getPraise = async (behavior: string): Promise<PraiseResult> => {
    try {
        const systemPrompt = 'ä½ æ˜¯ä¸€ä½çƒ­æƒ…çš„å•¦å•¦é˜Ÿé•¿ã€‚ç”¨ä¸€å¥è¯å’Œä¸€ä¸ªemojiåº†ç¥ç”¨æˆ·å®Œæˆäº†ä¹ æƒ¯ã€‚å›å¤JSONæ ¼å¼: {"message": "åº†ç¥è¯­", "emoji": "ğŸ‰"}';
        const response = await chatCompletion(systemPrompt, `ç”¨æˆ·å®Œæˆäº†: ${behavior}`);
        return JSON.parse(response);
    } catch {
        return { message: 'ä½ çœŸæ£’ï¼ç»§ç»­åŠ æ²¹ï¼', emoji: 'ğŸ‘' };
    }
};
