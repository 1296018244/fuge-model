/**
 * Cloud-based AI Service
 * Uses OpenAI API directly with settings from Supabase
 */
import { cloudSettings, cloudAIConfigs } from '../hooks/supabaseStorage';
import type { AnalysisResult, PraiseResult, AIConfig } from '../types';

// Get AI config from cloud (Prioritize new ai_configs table)
async function getAIConfig(): Promise<{ apiKey: string; baseUrl: string; model: string, configId?: string }> {
    // 1. Try get active config from new table
    const activeConfig = await cloudAIConfigs.getActive();
    if (activeConfig) {
        return {
            apiKey: activeConfig.api_key,
            baseUrl: activeConfig.base_url,
            model: activeConfig.model_name,
            configId: activeConfig.id
        };
    }

    // 2. Fallback to legacy settings
    const config = await cloudSettings.fetchAll();
    return {
        apiKey: config.openai_api_key || '',
        baseUrl: config.openai_base_url || 'https://api.openai.com/v1',
        model: config.model_name || 'gpt-3.5-turbo'
    };
}

// å°è¯•åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨é…ç½®
async function switchToNextConfig(currentConfigId?: string): Promise<boolean> {
    if (!currentConfigId) return false;

    const allConfigs = await cloudAIConfigs.fetchAll();
    if (allConfigs.length <= 1) return false;

    // æ‰¾åˆ°å½“å‰é…ç½®çš„ç´¢å¼•
    const currentIndex = allConfigs.findIndex(c => c.id === currentConfigId);
    let nextIndex = (currentIndex + 1) % allConfigs.length;

    // ç®€å•è½®è¯¢ï¼šæ‰¾ä¸‹ä¸€ä¸ª
    const nextConfig = allConfigs[nextIndex];
    if (nextConfig && nextConfig.id !== currentConfigId) {
        console.log(`[AI] Auto-switching to config: ${nextConfig.name}`);
        await cloudAIConfigs.setActive(nextConfig.id);
        return true;
    }
    return false;
}

// Generic chat completion call with retry
async function chatCompletion(systemPrompt: string, userMessage: string, retryCount = 0): Promise<string> {
    const { apiKey, baseUrl, model, configId } = await getAIConfig();

    console.log(`[AI] Calling ${baseUrl} with model ${model} (Attempt ${retryCount + 1})`);

    if (!apiKey) {
        throw new Error('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® OpenAI API Key');
    }

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 60000); // 60s timeout

    try {
        const response = await fetch(`${baseUrl}/chat/completions`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                model,
                messages: [
                    { role: 'system', content: systemPrompt },
                    { role: 'user', content: userMessage }
                ],
                temperature: 0.7
            }),
            signal: controller.signal
        });

        clearTimeout(timeoutId);

        if (!response.ok) {
            // Check for 429 Rate Limit
            if (response.status === 429 && retryCount < 3) {
                console.warn(`[AI] Rate limit exceeded (429). Trying next config...`);
                const switched = await switchToNextConfig(configId);
                if (switched) {
                    return chatCompletion(systemPrompt, userMessage, retryCount + 1);
                }
            }

            const errorText = await response.text();
            console.error('[AI] API Error:', response.status, errorText);

            let friendlyMessage = `AI æœåŠ¡è¯·æ±‚å¤±è´¥ (${response.status})`;
            if (response.status === 401) {
                friendlyMessage = 'API Key æ— æ•ˆæˆ–è¿‡æœŸï¼Œè¯·åœ¨è®¾ç½®ä¸­æ£€æŸ¥';
            } else if (response.status === 429) {
                friendlyMessage = 'å½“å‰é…ç½®è¯·æ±‚æ¬¡æ•°è¶…é™ï¼Œä¸”æ— å…¶ä»–å¯ç”¨é…ç½®';
            } else if (response.status >= 500) {
                friendlyMessage = 'AI æœåŠ¡å™¨å¼€å°å·®äº†ï¼Œè¯·ç¨åé‡è¯•';
            }

            try {
                const errorJson = JSON.parse(errorText) as import('../types').AIErrorResponse;
                const backendMsg = errorJson.error && typeof errorJson.error !== 'string'
                    ? errorJson.error.message
                    : (typeof errorJson.error === 'string' ? errorJson.error : '');

                throw new Error(backendMsg || friendlyMessage);
            } catch (e: unknown) {
                // If it's already the Error we threw above, rethrow it
                if (e instanceof Error && e.message !== friendlyMessage && !e.message.includes('JSON')) {
                    throw e;
                }
                throw new Error(`${friendlyMessage}: ${errorText.substring(0, 50)}...`);
            }
        }

        const data = await response.json() as import('../types').AIChatCompletionResponse;
        const content = data.choices?.[0]?.message?.content;

        if (!content) {
            console.warn('[AI] Empty response content:', data);

            // Check for provider specific errors (e.g. iflow.cn / siliconflow)
            const statusStr = String(data.status || '');
            if ((data.status && data.msg) || statusStr === '435') {
                const msg = data.msg || (data.error ? JSON.stringify(data.error) : 'Unknown Error');
                const isModelError = msg.includes('Model not support') || statusStr === '435';

                if (isModelError) {
                    console.warn(`[AI] Model error detected (${msg}). Trying next config...`);
                    const switched = await switchToNextConfig(configId);
                    if (switched) {
                        return chatCompletion(systemPrompt, userMessage, retryCount + 1);
                    }
                    throw new Error(`AI æœåŠ¡å•†æŠ¥é”™: ${msg} (è¯·æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®)`);
                }
                throw new Error(`AI æœåŠ¡å•†æŠ¥é”™: ${msg}`);
            }

            // Check generic 'error' field in 200 OK response
            if (data.error) {
                const errorMsg = typeof data.error === 'string' ? data.error : (data.error.message || JSON.stringify(data.error));
                throw new Error(`AI API æŠ¥é”™: ${errorMsg}`);
            }

            throw new Error('AI è¿”å›äº†ç©ºå†…å®¹ï¼Œä¸”æ— æ˜ç¡®é”™è¯¯ä¿¡æ¯');
        }

        return content;

    } catch (error: unknown) {
        clearTimeout(timeoutId);
        console.error('[AI] Request Failed:', error);

        if (error instanceof Error) {
            if (error.name === 'AbortError') {
                throw new Error('AI è¯·æ±‚è¶…æ—¶ (60ç§’)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•');
            }
            if (error.message === 'Failed to fetch') {
                throw new Error('æ— æ³•è¿æ¥åˆ° AI æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– Base URL è®¾ç½®');
            }
            throw error;
        }
        throw new Error(String(error));
    }
}

// Helper to clean markdown formatting from JSON string
function cleanJsonResponse(str: string): string {
    if (!str) return '{}';
    // Remove markdown code blocks: ```json, ``` json, ````json, etc. (any backticks, optional space, optional language tag)
    let cleaned = str.replace(/`{3,}\s*json\s*/gi, '').replace(/\s*`{3,}/g, '');
    // Sometimes there's explanation text before/after, try to find the first { and last }
    const firstBrace = cleaned.indexOf('{');
    const lastBrace = cleaned.lastIndexOf('}');
    if (firstBrace !== -1 && lastBrace !== -1) {
        cleaned = cleaned.substring(firstBrace, lastBrace + 1);
    }
    return cleaned.trim();
}

// Behavior analysis for BehaviorWizard
export const analyzeBehavior = async (
    behavior: string,
    motivation: number,
    ability: number
): Promise<AnalysisResult> => {
    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¡Œä¸ºè®¾è®¡é¡¾é—®ï¼ŒåŸºäºç¦æ ¼è¡Œä¸ºæ¨¡å‹å¸®åŠ©ç”¨æˆ·å»ºç«‹å¾®ä¹ æƒ¯ã€‚
    
è¯·åˆ†æç”¨æˆ·æƒ³è¦å»ºç«‹çš„è¡Œä¸ºï¼Œå¹¶æä¾›ï¼š
1. åˆ†æè¿™ä¸ªè¡Œä¸ºç›®å‰çš„å¯è¡Œæ€§
2. å»ºè®®ä¸€ä¸ªæ›´å¾®å°ã€æ›´å®¹æ˜“æ‰§è¡Œçš„ç‰ˆæœ¬
3. è®¾è®¡ä¸€ä¸ª"é”šç‚¹+å¾®è¡Œä¸º"çš„é…æ–¹

ä»¥çº¯JSONæ ¼å¼å›å¤ï¼ˆä¸è¦Markdownæ ¼å¼ï¼‰ï¼š
{
  "analysis": "å¯¹è¡Œä¸ºçš„ç®€çŸ­åˆ†æ",
  "suggestion": "å¦‚ä½•è®©è¿™ä¸ªè¡Œä¸ºæ›´å®¹æ˜“æ‰§è¡Œçš„å»ºè®®ï¼ˆmarkdownæ ¼å¼ï¼‰",
  "recipe": {
    "anchor": "è§¦å‘è¡Œä¸ºçš„é”šç‚¹ï¼Œå¦‚'å½“æˆ‘åˆ·å®Œç‰™å'",
    "tiny_behavior": "æç®€ç‰ˆæœ¬çš„è¡Œä¸ºï¼Œå¦‚'åš2ä¸ªæ·±è¹²'"
  },
  "environment_setup": ["ä¸ºæˆåŠŸå‡†å¤‡ç¯å¢ƒçš„å»ºè®®1", "å»ºè®®2"]
}`;

    const userMessage = `è¡Œä¸º: ${behavior}\nåŠ¨æœºåˆ†æ•°: ${motivation}/10\nèƒ½åŠ›åˆ†æ•°: ${ability}/10`;

    let response = '';
    try {
        response = await chatCompletion(systemPrompt, userMessage);
        const cleaned = cleanJsonResponse(response);
        console.log('[AI] Raw Response:', response);
        console.log('[AI] Cleaned Response:', cleaned);

        const parsed = JSON.parse(cleaned);
        return {
            behavior,
            score: Math.min(motivation, ability),
            suggestion: parsed.suggestion || '',
            analysis: parsed.analysis,
            recipe: parsed.recipe,
            environment_setup: parsed.environment_setup
        };
    } catch (e: any) {
        console.error('[AI] Parse Error:', e);

        // Fallback for JSON parse errors
        if (e.message?.includes('JSON')) {
            return {
                behavior,
                score: Math.min(motivation, ability),
                suggestion: `AI è¿”å›æ ¼å¼å¯èƒ½æœ‰è¯¯ï¼Œæ— æ³•è§£æä¸º JSONã€‚\n\nåŸå§‹å›å¤:\n${response}`,
                analysis: 'è§£æé”™è¯¯'
            };
        }
        throw e;
    }
};

// Diagnosis for DiagnosisModal (Legacy - kept for compatibility)
export const diagnoseFailure = async (habit: any, reason: string): Promise<any> => {
    const systemPrompt = `ä½ æ˜¯ä¸€ä½è¡Œä¸ºä¹ æƒ¯åŒ»ç”Ÿï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·è¯Šæ–­ä¸ºä»€ä¹ˆä¹ æƒ¯æ²¡æœ‰æ‰§è¡ŒæˆåŠŸï¼Œå¹¶æä¾›ä¿®å¤æ–¹æ¡ˆã€‚

æ ¹æ®ç”¨æˆ·æä¾›çš„ä¹ æƒ¯ä¿¡æ¯å’Œå¤±è´¥åŸå› ï¼Œç»™å‡ºï¼š
1. è¯Šæ–­ç»“æœ
2. ä¸€ä¸ªæ›´ç®€å•/æ›´é€‚åˆçš„æ–°æ–¹æ¡ˆ

ä»¥çº¯JSONæ ¼å¼å›å¤ï¼ˆä¸è¦Markdownæ ¼å¼ï¼‰ï¼š
{
  "diagnosis": "å¯¹å¤±è´¥åŸå› çš„ç®€çŸ­è¯Šæ–­",
  "new_plan": {
    "anchor": "æ–°çš„é”šç‚¹",
    "tiny_behavior": "æ›´ç®€å•çš„å¾®è¡Œä¸º"
  }
}`;

    const reasonMap: Record<string, string> = {
        'forgot': 'æˆ‘å¿˜è®°åšäº†',
        'hard': 'å¤ªéš¾äº†/å¤ªç´¯äº†',
        'unmotivated': 'è§‰å¾—æ²¡æ„ä¹‰',
        'ineffective': 'åšäº†ä½†æ²¡ç”¨'
    };

    const userMessage = `ä¹ æƒ¯ä¿¡æ¯ï¼š
- é”šç‚¹: ${habit.anchor}
- å¾®è¡Œä¸º: ${habit.tiny_behavior}
- åŸå§‹ç›®æ ‡: ${habit.original_behavior || '(æœªçŸ¥)'}

å¤±è´¥åŸå› : ${reasonMap[reason] || reason}`;

    let response = '';
    try {
        response = await chatCompletion(systemPrompt, userMessage);
        const cleaned = cleanJsonResponse(response);
        console.log('[AI] Diagnose Raw Response:', response);
        console.log('[AI] Diagnose Cleaned Response:', cleaned);
        return JSON.parse(cleaned);
    } catch (e: any) {
        console.error('[AI] Diagnose Error:', e);

        // Fallback for JSON parse errors
        if (e.message?.includes('JSON') || e.message?.includes('Unexpected')) {
            return {
                diagnosis: `AIè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œè¯·é‡è¯•ã€‚åŸå§‹å›å¤: ${response.substring(0, 100)}...`,
                new_plan: null
            };
        }
        throw e;
    }
};

// Message type for chat
export interface ChatMessage {
    role: 'user' | 'assistant' | 'system';
    content: string;
}

// Conversational diagnosis - multi-turn chat
export const diagnosisChat = async (
    habit: any,
    messages: ChatMessage[]
): Promise<{ reply: string; suggestion?: { anchor: string; tiny_behavior: string } }> => {
    const systemPrompt = `ä½ æ˜¯ç”¨æˆ·çš„å¥½æœ‹å‹ï¼ŒåŒæ—¶ä¹Ÿæ‡‚ä¸€ç‚¹è¡Œä¸ºå¿ƒç†å­¦ã€‚ç”¨æˆ·æ­£åœ¨å°è¯•å…»æˆä¸€ä¸ªä¹ æƒ¯ä½†é‡åˆ°äº†å›°éš¾ã€‚

ä½ çš„è§’è‰²ï¼š
- åƒæœ‹å‹ä¸€æ ·èŠå¤©ï¼Œä¸è¦å¤ªæ­£å¼
- å…ˆè¡¨è¾¾ç†è§£å’Œå…±æƒ…ï¼Œå†ç»™å»ºè®®
- å¯ä»¥é€‚å½“ç”¨emojiè®©å¯¹è¯æ›´è½»æ¾
- å¦‚æœç”¨æˆ·è¯´çš„ä¸å¤Ÿæ¸…æ¥šï¼Œå¯ä»¥è¿½é—®

ç”¨æˆ·æ­£åœ¨å°è¯•çš„ä¹ æƒ¯ï¼š
- é”šç‚¹: ${habit.anchor}
- å¾®è¡Œä¸º: ${habit.tiny_behavior}
${habit.original_behavior ? `- åŸå§‹ç›®æ ‡: ${habit.original_behavior}` : ''}

è¿‡å»çš„è¯Šæ–­è®°å½• (å‚è€ƒç”¨):
${(habit.diagnosis_log || []).map((log: any) =>
        `- [${log.date.split('T')[0]}] å»ºè®®: "${log.suggestion}". ç”¨æˆ·åé¦ˆ: ${log.feedback === 'helpful' ? 'æœ‰ç”¨ âœ…' : log.feedback === 'not_helpful' ? 'æ²¡ç”¨ âŒ' : 'æœªçŸ¥'}`
    ).join('\n')}

å¯¹è¯è§„åˆ™ï¼š
1. å¦‚æœä½ è§‰å¾—ä¿¡æ¯è¶³å¤Ÿäº†ï¼Œå¯ä»¥ç»™å‡ºå…·ä½“å»ºè®®
2. å¦‚æœéœ€è¦ç»™å‡ºæ–°æ–¹æ¡ˆï¼Œåœ¨å›å¤æœ«å°¾åŠ ä¸Šè¿™ä¸ªæ ¼å¼ï¼ˆç”¨æˆ·çœ‹ä¸åˆ°è¿™éƒ¨åˆ†ï¼Œç³»ç»Ÿä¼šè§£æï¼‰ï¼š
   [SUGGESTION]{"anchor": "æ–°é”šç‚¹", "tiny_behavior": "æ–°å¾®è¡Œä¸º"}[/SUGGESTION]
3. ä¸è¦æ¯æ¬¡éƒ½ç»™å»ºè®®ï¼Œå…ˆèŠå‡ å¥å†è¯´
4. å›å¤è¦ç®€çŸ­ï¼Œåƒå‘å¾®ä¿¡ä¸€æ ·ï¼Œä¸è¦å†™é•¿ç¯‡å¤§è®º`;

    const { apiKey, baseUrl, model } = await getAIConfig();

    if (!apiKey) {
        throw new Error('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® AI API Key');
    }

    const allMessages = [
        { role: 'system' as const, content: systemPrompt },
        ...messages
    ];

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 60000);

    try {
        const response = await fetch(`${baseUrl}/chat/completions`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                model,
                messages: allMessages,
                temperature: 0.8
            }),
            signal: controller.signal
        });

        clearTimeout(timeoutId);

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`AI è¯·æ±‚å¤±è´¥ (${response.status}): ${errorText.substring(0, 100)}`);
        }

        const data = await response.json() as import('../types').AIChatCompletionResponse;
        const content = data.choices?.[0]?.message?.content || '';

        // Parse suggestion if present
        const suggestionMatch = content.match(/\[SUGGESTION\](.*?)\[\/SUGGESTION\]/s);
        let suggestion: { anchor: string; tiny_behavior: string } | undefined;
        let reply = content;

        if (suggestionMatch) {
            try {
                suggestion = JSON.parse(suggestionMatch[1]);
                reply = content.replace(/\[SUGGESTION\].*?\[\/SUGGESTION\]/s, '').trim();
            } catch {
                // If parsing fails, just show the raw reply
            }
        }

        return { reply, suggestion };

    } catch (error: unknown) {
        clearTimeout(timeoutId);
        if (error instanceof Error) {
            if (error.name === 'AbortError') {
                throw new Error('è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ');
            }
            throw error;
        }
        throw new Error(String(error));
    }
};

// Praise for celebrations
export const getPraise = async (behavior: string): Promise<PraiseResult> => {
    try {
        const systemPrompt = 'ä½ æ˜¯ä¸€ä½çƒ­æƒ…çš„å•¦å•¦é˜Ÿé•¿ã€‚ç”¨ä¸€å¥è¯å’Œä¸€ä¸ªemojiåº†ç¥ç”¨æˆ·å®Œæˆäº†ä¹ æƒ¯ã€‚å›å¤JSONæ ¼å¼: {"message": "åº†ç¥è¯­", "emoji": "ğŸ‰"}';
        const response = await chatCompletion(systemPrompt, `ç”¨æˆ·å®Œæˆäº†: ${behavior}`);
        return JSON.parse(response);
    } catch {
        return { message: 'ä½ çœŸæ£’ï¼ç»§ç»­åŠ æ²¹ï¼', emoji: 'ğŸ‘' };
    }
};

// Weekly AI Review - analyzes habits and suggests improvements
export const weeklyReview = async (habits: any[]): Promise<{
    summary: string;
    highlights: string[];
    suggestions: string[];
    focusHabit?: string;
}> => {
    const systemPrompt = `ä½ æ˜¯ä¸€ä½è¡Œä¸ºè®¾è®¡æ•™ç»ƒï¼Œæ­£åœ¨ä¸ºç”¨æˆ·åšæ¯å‘¨å¤ç›˜ã€‚
åˆ†æç”¨æˆ·çš„ä¹ æƒ¯æ•°æ®ï¼Œç»™å‡ºé¼“åŠ±å’Œå»ºè®®ã€‚

å›å¤çº¯JSONæ ¼å¼ï¼š
{
  "summary": "ä¸€å¥è¯æ€»ç»“æœ¬å‘¨è¡¨ç°",
  "highlights": ["æˆå°±1", "æˆå°±2"],
  "suggestions": ["å»ºè®®1", "å»ºè®®2"],
  "focusHabit": "ä¸‹å‘¨é‡ç‚¹å…³æ³¨çš„ä¹ æƒ¯åç§°ï¼ˆå¯é€‰ï¼‰"
}`;

    const habitData = habits.map(h => ({
        name: h.tiny_behavior,
        streak: h.current_streak || 0,
        total: h.completed_count || 0,
        level: h.difficulty_level || 1,
        failures: h.consecutive_failures || 0
    }));

    const userMessage = `æœ¬å‘¨ä¹ æƒ¯æ•°æ®ï¼š\n${JSON.stringify(habitData, null, 2)}`;

    try {
        const response = await chatCompletion(systemPrompt, userMessage);
        const cleaned = cleanJsonResponse(response);
        return JSON.parse(cleaned);
    } catch (e) {
        console.error('[AI] Weekly review error:', e);
        return {
            summary: 'ç»§ç»­ä¿æŒï¼æ¯ä¸€å¤©çš„åšæŒéƒ½å¾ˆé‡è¦ã€‚',
            highlights: ['ä½ æ­£åœ¨å…»æˆå¥½ä¹ æƒ¯'],
            suggestions: ['ä¿æŒç®€å•ï¼ŒæŒç»­è¡ŒåŠ¨']
        };
    }
};
